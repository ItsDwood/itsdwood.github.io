<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Donovan Wood">
<meta name="dcterms.date" content="2024-03-27">
<meta name="description" content="My Blog Post Discussing the Limits of the Quantitative Approach to Bias and Fairness in Machine Learning.">

<title>Donovan’s Awesome CSCI 0451 Blog - Limits of the Quantitative Approach to Bias and Fairness</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Donovan’s Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Donovan’s Blog Post</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Limits of the Quantitative Approach to Bias and Fairness</h1>
                  <div>
        <div class="description">
          My Blog Post Discussing the Limits of the Quantitative Approach to Bias and Fairness in Machine Learning.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Donovan Wood </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 27, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This essay critically examines Arvind Narayanan’s assertion that quantitative methods used to assess bias and discrimination “primarily justify the status quo and do more harm than good.” By thoroughly exploring Narayanan’s arguments alongside related scholarly works and additional research, this analysis investigates the complex nature of quantitative methods in both perpetuating and addressing systemic biases.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Arvind Narayanan, in his 2022 speech, challenges the prevalent use of quantitative methods in discrimination research, arguing that these tools, rather than dismantling inequalities, often perpetuate them by reinforcing existing power dynamics. This essay engages with Narayanan’s critique by examining the potential benefits and significant limitations of quantitative methods as described in various scholarly works, including “Fairness and Machine Learning” by Barocas, Hardt, and Narayanan (2023), “Data Feminism” by D’Ignazio and Klein (2023), and three additional scholarly sources: “Machine Bias” by Julia Angwin et al.&nbsp;(2016), “Algorithmic Bias in Healthcare: The Case for Building Fairer Algorithms” by Isaac S. Lee (2018), and “Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor” by Virginia Eubanks (2018). This analysis investigates the complex nature of quantitative methods in both perpetuating and addressing systemic biases, providing a nuanced discussion on how these methodologies shape and are shaped by societal structures.</p>
</section>
<section id="narayanans-position" class="level1">
<h1>Narayanan’s Position</h1>
<p>In his 2022 speech, Arvind Narayanan presents a deeply critical view of the role of quantitative methods in the study and mitigation of discrimination. Narayanan <span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span> argues that these methods, commonly perceived as objective and neutral, are frequently co-opted to serve entrenched social and economic interests rather than to challenge them. His contention is that instead of dismantling the structures of bias and inequality, quantitative approaches often merely redefine these injustices in more scientifically palatable terms.</p>
<p>Narayanan’s critique centers on the idea that quantitative methods can obscure the subjective and context-dependent nature of social injustices. By translating complex human experiences and systemic inequalities into numerical data, these methods strip away the nuances that are essential for a true understanding of the issues at hand. This translation process can result in oversimplified models of reality that fail to capture the underlying dynamics of discrimination.</p>
<p>Narayanan points out that the reliance on data-driven approaches often leads to what he describes as a “techno-solutionism” mindset, where technological fixes are sought for problems that are essentially social and political in nature. This belief in the neutrality of technology can be dangerously misleading, as it assumes that algorithms and data are inherently unbiased, ignoring the ways in which they can reflect and perpetuate existing prejudices.</p>
<p>A pivotal aspect of Narayanan’s argument is the critique of how these methods are implemented in practice. He observes that statistical and computational tools are frequently used to make incremental changes that do not threaten the status quo. For instance, when biases in hiring practices are quantitatively assessed, the solutions often focus on minor tweaks in algorithms or data sets rather than addressing the broader societal and organizational cultures that foster discrimination.</p>
<p>Narayanan also critiques the political dimension of quantitative methods. He argues that these tools can be used to create an illusion of fairness and impartiality, thus serving as a powerful means of legitimizing and reinforcing existing power structures. By presenting discrimination as a technical issue to be solved through better data or algorithms, the deeper, more uncomfortable conversations about structural inequalities and power imbalances are conveniently sidestepped.</p>
<p>Narayanan’s calls for a more reflective approach to the use of data and technology, one that recognizes the inherent subjectivities involved and prioritizes the voices and experiences of those most affected by discrimination. This approach would not reject the use of quantitative methods outright but would integrate them into a broader, more critically aware framework of analysis.</p>
</section>
<section id="the-benefits-of-quantitative-methods" class="level1">
<h1>The Benefits of Quantitative Methods</h1>
<p>Quantitative methods are invaluable for their ability to deliver objective, measurable insights, crucial in fields traditionally influenced by subjective biases, such as recruitment and law enforcement. As outlined in “Fairness and Machine Learning” by Barocas, Hardt, and Narayanan <span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>, these methods enable the identification and rectification of biases within algorithms. For instance, statistical tools can uncover and correct discriminatory practices in hiring by analyzing patterns in data that might not be visible to human recruiters.</p>
<p>Additionally, these methods enhance the scalability and efficiency of data analysis, which is essential in managing the vast volumes of data typical in sectors like healthcare and public policy. This capability allows for the detection of trends and anomalies that would be impractical to identify manually, facilitating proactive interventions in public health and resource allocation.</p>
<p>Quantitative methods also promote transparency and accountability, particularly in algorithmic decision-making. Tools such as confusion matrices and ROC curves provide clear metrics for evaluating an algorithm’s fairness and accuracy, making it easier to ensure compliance with ethical standards and legal regulations. This transparency is vital for building trust among users and stakeholders, affirming that the systems in place do not perpetuate existing inequalities.</p>
<p>The iterative nature of quantitative analysis supports continuous improvement. As new data becomes available and social dynamics evolve, these methods help adjust algorithms to maintain fairness and effectiveness. The integration of quantitative and qualitative insights, as recommended in both “Fairness and Machine Learning” and “Data Feminism” <span class="citation" data-cites="dignazio2023datafeminism">D’Ignazio and Klein (<a href="#ref-dignazio2023datafeminism" role="doc-biblioref">2023</a>)</span>, enriches our understanding of biases, ensuring that solutions address both the symptoms and root causes of discrimination.</p>
</section>
<section id="the-limitations-of-quantitative-methods" class="level1">
<h1>The Limitations of Quantitative Methods</h1>
<p>While quantitative methods are lauded for their ability to provide empirical evidence and standardize assessments, they harbor significant limitations that can undermine their effectiveness in addressing social inequalities. One of the fundamental criticisms, as underscored in “Data Feminism” by D’Ignazio and Klein <span class="citation" data-cites="dignazio2023datafeminism">D’Ignazio and Klein (<a href="#ref-dignazio2023datafeminism" role="doc-biblioref">2023</a>)</span>, is the risk of decontextualization. Quantitative methods often strip data of its context, reducing complex human experiences and societal issues to mere numbers. This abstraction can lead to a misleading representation of reality, where the nuances of individual and community experiences are lost. For example, when measuring income disparities across different demographic groups, quantitative methods might successfully highlight averages and trends but fail to account for underlying causes such as historical discrimination, access to education, or regional economic conditions.</p>
<p>These methods can create a veneer of objectivity and neutrality, masking the subjective decisions involved in data collection, analysis, and interpretation. Every step in a quantitative analysis, from choosing which variables to measure to deciding how to categorize data, involves subjective choices that can introduce bias. This is particularly problematic in fields where data is inherently biased due to historical or social prejudices, as is often the case with criminal justice data used in predictive policing algorithms. These systems, designed to predict future crimes, may instead perpetuate past injustices by targeting communities that have been historically over-policed.</p>
<p>Another significant limitation of quantitative methods is their focus on correlation rather than causation. This can lead to scenarios where algorithms make decisions based on patterns in data that are not causally linked to the outcomes they predict. For instance, an employment algorithm might downgrade a candidate’s suitability for a job based on zip code, not because the zip code itself has any bearing on job performance but because historical data shows a correlation between certain zip codes and lower job retention rates. Such practices not only reinforce existing stereotypes but also avoid addressing the root causes of these correlations.</p>
<p>Quantitative methods also often fail to capture the feedback loops that can exacerbate social inequalities. For example, if a loan approval algorithm uses historical data showing higher default rates in a certain demographic, it may lead to fewer loans being offered to people from that demographic. This, in turn, can limit economic opportunities for that group, perpetuating and even worsening the disparity. The algorithm’s decisions thus become a self-fulfilling prophecy, embedding inequalities deeper into the system.</p>
<p>The over-reliance on quantitative methods can divert attention and resources away from qualitative insights and more holistic approaches to understanding and solving social issues. It can encourage a tick-box mentality where meeting numerical targets is seen as sufficient, even if the underlying issues remain unresolved. This approach undermines efforts to address the deeper, structural aspects of discrimination and bias, which are often better illuminated through qualitative research and direct engagement with affected communities.</p>
<p>While quantitative methods can offer valuable insights, their limitations underscore the need for a balanced approach that combines quantitative data with qualitative analysis and ethical consideration. This more nuanced approach can help ensure that efforts to address bias and discrimination do not inadvertently perpetuate the very injustices they aim to eradicate.</p>
</section>
<section id="expanding-on-limitations-with-additional-scholarly-sources" class="level1">
<h1>Expanding on Limitations with Additional Scholarly Sources</h1>
<p>While quantitative methods offer significant analytical power, their limitations become especially pronounced when highlighted by real-world applications. For instance, Julia Angwin and her team at ProPublica <span class="citation" data-cites="angwin2016machine">Angwin et al. (<a href="#ref-angwin2016machine" role="doc-biblioref">2016</a>)</span> expose how risk assessment tools used in the criminal justice system, intended to provide unbiased judgments, actually perpetuate racial biases. Their investigation revealed that these tools predict higher recidivism rates for Black defendants compared to White defendants, despite similar circumstances. This example underscores the critical issue of inherent biases in the data sets used for creating and training algorithms, which can amplify rather than reduce discrimination.</p>
<p>In the context of healthcare, Isaac Lee’s research in “Algorithmic bias in healthcare: the case for building fairer algorithms” <span class="citation" data-cites="lee2018algorithmic">Lee (<a href="#ref-lee2018algorithmic" role="doc-biblioref">2018</a>)</span> illustrates another dimension of algorithmic bias. Lee points out that most medical algorithms are developed using data predominantly from white populations, which can lead to inaccurate diagnoses or treatments for patients of other ethnic backgrounds. This not only compromises the effectiveness of healthcare delivery but also raises significant ethical concerns about equity and access to medical care.</p>
<p>Virginia Eubanks in “Automating Inequality” <span class="citation" data-cites="eubanks2018automating">Eubanks (<a href="#ref-eubanks2018automating" role="doc-biblioref">2018</a>)</span> further explores how automated systems used in public services systematically disadvantage the poor. Eubanks documents instances where algorithms determine the distribution of welfare benefits, often resulting in denials or reductions of aid based on flawed data interpretations. These cases reveal how quantitative methods can inadvertently entrench socio-economic disparities by failing to account for complex human needs and the contextual factors affecting those in poverty.</p>
<p>These examples from diverse sectors illustrate a common theme: quantitative methods, while powerful, often lack the sensitivity to contextual nuances and the diversity of human experience. They can create feedback loops where initial biases are reinforced, leading to cycles of inequality. This is particularly problematic in systems where algorithmic decisions have significant impacts on people’s lives, such as in justice, healthcare, and social welfare. Each of these sectors shows how crucial it is to integrate qualitative assessments and stakeholder engagement into the quantitative analysis process to mitigate these limitations.</p>
</section>
<section id="conclusion-and-position" class="level1">
<h1>Conclusion and Position</h1>
<p>Reflecting on the evidence and arguments presented, this essay acknowledges the validity of Narayanan’s concerns with qualifications. Quantitative methods, while powerful, can indeed reinforce the status quo if not used thoughtfully. However, when combined with qualitative insights and ethical considerations, they can be instrumental in identifying and mitigating biases. The challenge lies in the responsible application of these tools, ensuring they are part of a broader, multidisciplinary approach to understanding and addressing discrimination.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-angwin2016machine" class="csl-entry" role="listitem">
Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. <span>“Machine Bias.”</span> <em>ProPublica</em>.
</div>
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. Cambridge, Massachusetts: The MIT Press.
</div>
<div id="ref-dignazio2023datafeminism" class="csl-entry" role="listitem">
D’Ignazio, Catherine, and Lauren Klein. 2023. <em>Data Feminism</em>. Cambridge, Massachusetts: MIT Press.
</div>
<div id="ref-eubanks2018automating" class="csl-entry" role="listitem">
Eubanks, Virginia. 2018. <em>Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</em>. New York: St. Martin’s Press.
</div>
<div id="ref-lee2018algorithmic" class="csl-entry" role="listitem">
Lee, Isaac S. 2018. <span>“Algorithmic Bias in Healthcare: The Case for Building Fairer Algorithms.”</span> <em>Health Affairs</em>.
</div>
<div id="ref-narayanan2022limits" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>